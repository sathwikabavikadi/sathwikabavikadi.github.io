@inproceedings{10.1145/3386263.3407649,
author = {Bavikadi, Sathwika and Sutradhar, Purab Ranjan and Khasawneh, Khaled N. and Ganguly, Amlan and Pudukotai Dinakarrao, Sai Manoj},
title = {A Review of In-Memory Computing Architectures for Machine Learning Applications},
year = {2020},
isbn = {9781450379441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386263.3407649},
doi = {10.1145/3386263.3407649},
abstract = {to meet the extensive computational load presented by the rapidly growing Machine Learning (ML) and Artificial Intelligence (AI) algorithms such as Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs). In order to obtain hardware solutions to meet the low-latency and high-throughput computational demands from these algorithms, Non-Von Neumann computing architectures such as In-memory Computing (IMC)/ Processing-in-memory (PIM) are being extensively researched and experimented with. In this survey paper, we analyze and review pioneer IMC/PIM works designed to accelerate ML algorithms such as DNNs and CNNs. We investigate different architectural aspects and dimensions of these works and provide our comparative evaluations. Furthermore, we discuss challenges and limitations in IMC research and also present feasible directions based on our observations and insight.},
booktitle = {Proceedings of the 2020 on Great Lakes Symposium on VLSI},
pages = {89â€“94},
numpages = {6},
keywords = {in-memory computing, artificial intelligence, non-von-neumann architectures, dnn, machine learning, cnn, processing-in-memory},
location = {Virtual Event, China},
series = {GLSVLSI '20}
}
